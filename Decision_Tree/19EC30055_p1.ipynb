{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYFXk44IRLod"
   },
   "source": [
    "## Machine Learning - CS60050\n",
    "### Roll No: 19EC30055\n",
    "### Name: Ujwal Nitin Nayak\n",
    "### Assignment No: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1644390024490,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "O8rnYXa2RLom"
   },
   "outputs": [],
   "source": [
    "import numpy as np #For mathematical functions\n",
    "import pandas as pd #For handling imported data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Training Data and Storing in Pandas DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1644390024493,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "RuJMk3WMRLoo",
    "outputId": "6fac8c26-6b65-427e-e051-37c01a9aa599"
   },
   "outputs": [],
   "source": [
    "attribute_names=['price','maint','doors','persons','lug_boot','safety','class']\n",
    "df=pd.read_csv('project1.data',header=None,names=attribute_names);\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Entropy Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vb3VG39IRLoq"
   },
   "source": [
    "At every level of the tree, we need to find the attribute providing the maximum information\n",
    "gain. The information gain calculation requires calculation of Shannon entropy which is done using the get_entropy function. The get_entropy function takes the classification column of the entire dataset (root level) or its subset (for lower levels) and calculates the entropy of the dataset remaining at a particular level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1644390024495,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "Z4mVIVmlRLor"
   },
   "outputs": [],
   "source": [
    "def get_entropy(target):\n",
    "    #Finding the counts of all unique elements in the target column\n",
    "    _,counts=np.unique(target,return_counts=True)\n",
    "    tot_count=np.sum(counts)\n",
    "    entropy=0.0\n",
    "    for i in range(len(counts)):\n",
    "        #Finding probability corresponding to each count\n",
    "        p=counts[i]/tot_count\n",
    "        #Plugging in the probabilities into the entropy formula\n",
    "        entropy+=((-p)*np.log2(p))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Information Gain Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIwoVoBiRLos"
   },
   "source": [
    "Now, let us calculate the information gain for a given attribute using the get_info_gain function. This function takes three arguments. The training data (could be the entire dataset or its subset), the attribute for which information gain is to be calculated, that is, the attribute over which the dataset is being split and the target attribute in relation to whose values the gain is being calculated. For this dataset, the target is the 'class' attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1644390024497,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "-dx6OpkBRLot"
   },
   "outputs": [],
   "source": [
    "def get_info_gain(data,attribute,target='class'):\n",
    "    #Calculating entropy of entire dataset\n",
    "    dataset_entropy = get_entropy(data[target])\n",
    "    #Calculating probabilistic entropy for the split attribute\n",
    "    values,counts=np.unique(data[attribute],return_counts=True)\n",
    "    tot_count=np.sum(counts)\n",
    "    probabilistic_entropy=0.0\n",
    "    for i in range(len(counts)):\n",
    "        #Finding probability of the particular class value\n",
    "        p=counts[i]/tot_count\n",
    "        subset=data.where(data[attribute]==values[i]).dropna()\n",
    "        #Fining entropy of reduced dataset\n",
    "        entropy_attr=get_entropy(subset[target])\n",
    "        #Adding probability weighted entropies\n",
    "        probabilistic_entropy+=p*entropy_attr\n",
    "    #Subtracting the weighted entropy from the dataset (or subset based on the level of tree) entropy\n",
    "    info_gain=dataset_entropy-probabilistic_entropy\n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the Decision Tree Algorithm and Fitting the Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9v1ubFRRLow"
   },
   "source": [
    "Finally, let us define the decision_tree function to build the Decision Tree using the ID3 algorithm. It takes 5 arguments.\n",
    "- fullset - The complete dataset\n",
    "- data - The subset of the data that is available at a given level\n",
    "- attributes - Set of all the attributes of the dataset present at a given level\n",
    "- target - The tagert attribute\n",
    "- parent_class - The class label of the attribute immediately before the current attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1644390024499,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "y7XUR4FVRLox"
   },
   "outputs": [],
   "source": [
    "def decision_tree(fullset,data,attributes,target='class',parent_class=None):\n",
    "    #3 base cases to terminate the recursion\n",
    "    #If the target values are all the same, the branching must stop and example should be\n",
    "    #classified as this target value\n",
    "    if len(np.unique(data[target]))<=1:\n",
    "        return np.unique(data[target])[0]\n",
    "    #The dataset at this level may be empty in which case the maximally occuring class label in\n",
    "    #the original dataset becomes the \n",
    "    elif len(data)==0:\n",
    "        _,counts=np.unique(fullset[target],return_counts=True);\n",
    "        return np.unique(fullset[target])[np.argmax(counts)]\n",
    "    #If all the attributes are exhausted, the maximally occuring class label of the parent is \n",
    "    #the answer\n",
    "    elif len(attributes)==0:\n",
    "        return parent_class\n",
    "    else:\n",
    "        #Finding the best attribute to choose using information gain concept\n",
    "        ig_arr=[];\n",
    "        for attr in attributes:\n",
    "            ig=get_info_gain(data,attr,target)\n",
    "            ig_arr.append(ig);\n",
    "        chosen_attr=attributes[np.argmax(ig_arr)]\n",
    "        \n",
    "        #Setting default value of the current node to the maximally occuring class label\n",
    "        _,counts=np.unique(data[target],return_counts=True)\n",
    "        parent_class=np.unique(data[target])[np.argmax(counts)]\n",
    "        \n",
    "        #Adding attribute to the tree \n",
    "        tree={chosen_attr:{}}\n",
    "        \n",
    "        #Removing chosen_attr from attributes using remove function\n",
    "        attributes=[attr for attr in attributes if attr is not chosen_attr]\n",
    "        \n",
    "        #Adding branches to the tree below the chosen attribute\n",
    "        values=np.unique(data[chosen_attr])\n",
    "        #Generating subtree below each of the possible attribute values\n",
    "        for val in values:\n",
    "            #Segmenting the data to contain only those examples with attribute value fixed to val\n",
    "            subset=data.where(data[chosen_attr]==val).dropna()\n",
    "            #Making a recursive call to work on subtrees\n",
    "            subtree=decision_tree(fullset,subset,attributes,target,parent_class)\n",
    "            #Assigning the subtree to the corresponding value of the chosen attribute\n",
    "            tree[chosen_attr][val]=subtree\n",
    "            \n",
    "        return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCxXwT-eRLo0"
   },
   "source": [
    "The Decision Tree Classifier is trained to fit the given training data and is stored in the dictionary variable tree. The arguments passed to the function are:\n",
    "- fullset = complete training set df\n",
    "- data = complete training set df, since in level 0 (root), the entire dataset is under consideration\n",
    "- attributes = all column headers except the class column df.column[:-1]\n",
    "- target = since the 'class' column is the classification column, the default value is taken\n",
    "- parent_class = since the root node has no parent and hence no parent class, default value None is taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4274,
     "status": "ok",
     "timestamp": 1644390028756,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "xLkBXZuHRLo2"
   },
   "outputs": [],
   "source": [
    "#Training the decision treee on the dataframe of training examples\n",
    "tree=decision_tree(df,df,df.columns[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a Function to Print the Decision Tree and Printing it in the Specified Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the tree is trained to fit the training examples, we need to define a function to print in a manner that is easy to read and interpret. For this the following function is implemented. It takes two arguments:\n",
    "- tree = dictionary of tree elements (attribute nodes are mapped to their values and further to their subtrees)\n",
    "- indent = the level of the tree which is used to decide the indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1644390028757,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "DEuaWodSRLo3"
   },
   "outputs": [],
   "source": [
    "#Print function\n",
    "def dtprint(tree,indent=0):\n",
    "    #Base case - if the tree specified is a string then the string is printed. Since the dictionary consists of node \n",
    "    #values followed by the subtree, this occurs when the tree has been traversed completely until the leaf attribute\n",
    "    #and the mapping contains only the node value and no subsequent tree\n",
    "    if isinstance(tree,str):\n",
    "        print(': ',tree)\n",
    "    else:\n",
    "        #List of keys contains only one element at every stage which is the attribute at that level of the tree\n",
    "        key=list(tree.keys())[0]\n",
    "        #Iterating over the the possible values that the attribute can take\n",
    "        for val in list(tree[key]):\n",
    "            #Setting indentations based on the example given in the project pdf\n",
    "            for i in range(indent):\n",
    "                if i==0:\n",
    "                    continue\n",
    "                print('\\t',end=\"\")\n",
    "            if indent>=1:\n",
    "                print('| ',end=\"\")\n",
    "            #Printing the attribute name \n",
    "            print(key,' = ',end=\"\")\n",
    "            #Printing the attribute value\n",
    "            print(val,end=\"\")\n",
    "            #Finding if the next value is a subtree (list type) or a verdict (string type)\n",
    "            if not isinstance(tree[key][val],str):\n",
    "                print()\n",
    "            dtprint(tree[key][val],indent+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us print the tree using the above function. The function call consists of only the tree and indent is 0 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1644390028758,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "2g9lmKsmRLo4",
    "outputId": "a42b85ff-28d3-4431-8995-2a140cdf69e3"
   },
   "outputs": [],
   "source": [
    "dtprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Test Data and Making Predictions Using the Trained Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1644390028759,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "Ri5bfk60RLo5",
    "outputId": "3c43a571-68ae-49b4-f448-7396966195bf"
   },
   "outputs": [],
   "source": [
    "attribute_names=['price','maint','doors','persons','lug_boot','safety','class']\n",
    "df_test=pd.read_csv('project1_test.data',header=None,names=attribute_names)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1644390029387,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "kRhlAnmBRLo7",
    "outputId": "703e5335-7e83-4679-fd90-2724a67f0c6c"
   },
   "outputs": [],
   "source": [
    "#Cleaning error in data - change 56 to 6 in doors attribute\n",
    "df_test['doors']=df_test['doors'].replace({56:6});\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the predictions, the find_class function is defined which takes in the following parameters\n",
    "- entry = each example in the test set converted in a records style dictionary\n",
    "- tree = trained decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1644390029388,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "JnA4hNv7RLo8"
   },
   "outputs": [],
   "source": [
    "def find_class(entry,tree):\n",
    "    #The entry dictionary consists of attribute-value pairs corresponding to each row of the test dataframe\n",
    "    #Iterating over these keys and finding if the subtree (full tree in first run) at this stage consists \n",
    "    #of this key\n",
    "    for key in list(entry.keys()):\n",
    "        if key in list(tree.keys()):\n",
    "            #If the key exists in the list of subtree keys, the subtree for the next recursion will become that branch \n",
    "            #of the subtree (having the entry attribute as the parent) which has entry attribute=entry value. This will\n",
    "            #occur in the same order as that in the tree \n",
    "            \n",
    "            #Example: In the first run, the only attribute in the list of tree keys is 'safety'. When entry keys are \n",
    "            #read, no operation will be perfomed until the 'safety' attribute is under consideration. If, suppose, the\n",
    "            #attribute value is 'high', the subtree for the next recursion will be that under safety=high\n",
    "            result=tree[key][entry[key]]\n",
    "            #If the subtree (result) selected for the next operation is not a dictionary but a string value, a leaf  \n",
    "            #node is reached and the result is returned. If it is a dictionary, recursion occurs and the for loop is\n",
    "            #run again to find the value of the root attribute of the subtree in the entry\n",
    "            \n",
    "            #Example: Suppose after safety=high, the next attribute is 'price' in the subtree. So the for loop will\n",
    "            #run until the price attribute of entry is found. Let the value of this attribute in entry be 'high'.\n",
    "            #Then the subtree with price=high will be selected as shown below (... represents subtree)\n",
    "            #safety='high'\n",
    "            #|price='vhigh'\n",
    "            #...\n",
    "            #|price='high'  <- selected for next recursion step\n",
    "            #...\n",
    "            #|price='med'\n",
    "            #...\n",
    "            #|price='low'\n",
    "            #...\n",
    "            #safety='mid'\n",
    "            #...\n",
    "            #safety='low'\n",
    "            #...\n",
    "            \n",
    "            #If the subtree is a single string value, the leaf node\n",
    "            #is reached and result (prediction) is returned. Otherwise the process repeats. \n",
    "            if isinstance(result,dict):\n",
    "                return find_class(entry,result)\n",
    "            else:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test function is used to manipulate the test data and store it in a form suitable for find_class function. This function also prints the predicted class next to the test examples and calculates the accuracy. The function takes in two arguments:\n",
    "- data = test examples\n",
    "- tree = trained decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1644390029389,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "4ZaGuICLRLo9"
   },
   "outputs": [],
   "source": [
    "def test(data,tree):\n",
    "    #Taking all columns from test data except the final column\n",
    "    data_no_class=data.iloc[:,:-1]\n",
    "    #Converting the data into a dictionary with each row represented as a list of attribute-value pairs\n",
    "    entries=data_no_class.to_dict(orient='records')\n",
    "    #Creating a dataframe for the predicted class values\n",
    "    predicted_class=pd.DataFrame(columns=['predicted_class'])\n",
    "    #Finding class for each entry and adding the result to predicted_class dataframe\n",
    "    for i in range(len(data)):\n",
    "        predicted_class.loc[i,'predicted_class']=find_class(entries[i],tree)\n",
    "    #Concatenating data and predicted_class dataframes\n",
    "    data_with_preds=pd.concat([data,predicted_class],axis=1)\n",
    "    print(data_with_preds)\n",
    "    #Calculating accuracy by calculating the percentage of entries in which the given class and predicted class\n",
    "    #have matched\n",
    "    accuracy=(np.sum(predicted_class['predicted_class']==data['class'])/len(data))*100;\n",
    "    print('Accuracy = ',accuracy,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1644390029389,
     "user": {
      "displayName": "Ujwal Nayak",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgOFrWSHLSRMvR4JExKz0qwSihXyedpBbi_4cHRiw=s64",
      "userId": "10726071225153001845"
     },
     "user_tz": -330
    },
    "id": "NHO6HxUhRLo9",
    "outputId": "8c68df77-1a77-4181-d2aa-8b82772fb8f6"
   },
   "outputs": [],
   "source": [
    "test(df_test,tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can see that the decision tree classifier trained on the training examples has successfully classified all\n",
    "the testset examples with 100% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------END--------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "19EC30055_p1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
