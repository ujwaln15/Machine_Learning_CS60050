{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - CS60050\n",
    "### Roll No: 19EC30055\n",
    "### Name: Ujwal Nitin Nayak\n",
    "### Assignment No: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The K-Nearest Neighbours algorithm is a non-parametric supervised learning algorithm which can be used both as classifier and a regressor. This algorithm assumes that two instances are similar if they exist in close proximity. \n",
    "- Unlike a decision tree, it does not use the training data to build a model and there is no requirement to tune several parameters or make any assumptions. \n",
    "- For a classification problem, every time a test example is encountered, the proximity or distance of this example to the training set examples is calculated, the k closest neighbours are chosen and then weights are assigned to each training example. This weight is typically an inverse distance weighting. The weights corresponding to each class are then summed up and the class with the highest summed weight is used to label the test example.\n",
    "- Proximity between a training example and a test example can be found using one of several distance metrics namely Minkowski, Manhattan, Euclidean, Chebyshev, Mahalanobis, etc. In this assignment, we will use the Euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #For mathematical functions\n",
    "import pandas as pd #For handling imported data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Training Data and Storing Attribute Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('project2.csv')\n",
    "attributes=df.columns.values.tolist();\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Target Labels and Dropping the Target Column from the Training DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=df.iloc[:,len(attributes)-1].values;\n",
    "df=df.drop(columns=['target']);\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('project2_test.csv');\n",
    "df_test.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization of Data using Z-Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the KNN algorithm is a distance-based algorithm, it is very prone to errors due to different ranges of features. Feature scaling using standardization ensures that all the values are centred around the mean with unit standard deviation, that is, the mean of the attribute becomes zero and the resultant distribution has a unit standard deviation. \n",
    "Feature scaling is done using the functions standardize_train and standardize_test. \n",
    "The standardize_train function takes the training data as its argument and finds the mean and standard deviation of each column, subtracts this mean from each column entry and then divides the entries by the standard deviation. The standardize_test functions uses the mean and standard deviation obtained for each of the columns of the training set and uses these to standardize the test set examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing Training Data\n",
    "def standardize_train(df):\n",
    "    norm_vals=[];\n",
    "    #Looping over columns\n",
    "    for col in df.columns:\n",
    "        mean=df[col].mean()           #Finding mean\n",
    "        std=df[col].std()             #Finding standard deviation\n",
    "        #Standardizing and storing mean and standard deviation values for test set standardization\n",
    "        df[col]=(df[col]-mean)/std;   \n",
    "        norm_vals.append(np.array([mean,std])); \n",
    "    return norm_vals;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing Test Data\n",
    "def standardize_test(df_test,norm_vals):\n",
    "    cnt=0;\n",
    "    #Using mean and standard deviation of corresponding column of training set to standardize test set\n",
    "    for col in df_test.columns:\n",
    "        mean=norm_vals[cnt][0];\n",
    "        std=norm_vals[cnt][1];\n",
    "        df_test[col]=(df_test[col]-mean)/std;\n",
    "        cnt+=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling standardize functions\n",
    "norm_vals=standardize_train(df);\n",
    "standardize_test(df_test,norm_vals);\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the values of each row of the dataframes into numpy arrays\n",
    "examples=df.values;\n",
    "test_examples=df_test.values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examples.shape)\n",
    "print(test_examples.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function euclidean is used to calculate the Euclidean distance between a row of the training and the test sets. \n",
    "The input arguments are row_test and row_train. First, the squared differences between corresponding attribute values of row_test and row_train are calculated and then summed over all attributes. The square root of this sum gives the distance between the examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(row_test,row_train):\n",
    "    distance=np.sum((row_test-row_train)**2);\n",
    "    return np.sqrt(distance);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest neighbours are found using the find_nearest_neighbours function. This function takes the training examples, one row of the test examples and the value of k as its arguments and performs the following:\n",
    "- Calls the euclidean function to find the distance between every training example and the current test example.\n",
    "- Stores the index of the training example and the distance in a list.\n",
    "- Sorts the list in increasing order based on the distance value.\n",
    "- Returns the first k elements of the sorted list of neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_neighbours(examples,entry,k):\n",
    "    neighbours=[];\n",
    "    idx=0; #Variable to keep track of the index\n",
    "    #Looping over all rows in the training example\n",
    "    for row in examples:\n",
    "        #Calling euclidean function to find distance \n",
    "        dist=euclidean(entry,row);\n",
    "        #Appending index and distance to the list\n",
    "        neighbours.append((idx,dist));\n",
    "        #Incrementing the index\n",
    "        idx+=1;\n",
    "    #Sorting based on the second parameter (dist)\n",
    "    neighbours.sort(key=lambda x:x[1]);\n",
    "    #Slicing first k elements\n",
    "    nearest_neighbours=neighbours[:k];\n",
    "    return nearest_neighbours;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights are assigned to the k nearest neighbours using the get_weights function which takes these neighbours and the number of training examples as its arguments. It does the following:\n",
    "- Initialises an empty list of weights with size equal to the number of training examples.\n",
    "- Loops over all the nearest neighbours and assigns (1/distance)^2 weight to the training example having a given index.\n",
    "- Returns the list of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(neighbours,sz):\n",
    "    weights=[None]*sz;\n",
    "    for idx,dist in neighbours:\n",
    "        weights[idx]=(1/(dist**2));\n",
    "    return weights;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Driver Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes the training examples, corresponding labels and the test examples as its arguments and does the following:\n",
    "- Sets the value of k (through user input alongwith a default value) for the find_nearest_neighbour function. While there is no optimal way to choose the value of k, a rule of thumb is to choose floor(sqrt(n)) where n is the the number of training examples. If this comes out to be even, it is usually incremented or decremented by 1. In this assignment, incrementation is chosen (but for the given training examples the if block is not used since floor(sqrt(299)) = 17 which is odd).\n",
    "- Obtains the k closest neighbours using the find_nearest_neighbour function and uses the index parameter of the  index,distance pair to find the corresponding labels. \n",
    "- Obtains the weights corresponding to these indices using the get_weights function and then finds the weighted distance for each of the possible output values\n",
    "- Sorts the list of weighted distances in decreasing order based on the sum_weights parameter and stores the label with highest weighted distance as the prediction for that particular row.\n",
    "- Returns the list of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(examples,labels,test_examples):\n",
    "    #Taking k as user input\n",
    "    k=input(\"Enter the value of k (1-\" +str(len(examples))+\") (enter 0 to use default value) \");\n",
    "    k=int(np.floor(float(k)));\n",
    "    #Setting default value of k as the floor(sqrt(no_of_training_examples))\n",
    "    if (k<0 or k>len(examples)):\n",
    "        print('Value outside range, taking default value');\n",
    "        k=0;\n",
    "    if(k==0):\n",
    "        k=int(np.floor(np.sqrt(len(examples))));\n",
    "        if(k%2==0):\n",
    "            k=k+1;\n",
    "    print('Value of k = ',end=\"\");\n",
    "    print(k);\n",
    "    #Defining the list of predictions\n",
    "    predictions=list();\n",
    "    #Looping over each row of the test set\n",
    "    for entry in test_examples:\n",
    "        #Finding the k nearest neighbours\n",
    "        neighbours=find_nearest_neighbours(examples,entry,k);\n",
    "        #Storing labels corresponding to these neighbours in a list\n",
    "        outputs=[labels[idx] for idx,dist in neighbours];\n",
    "        #Finding the unique values and corresponding counts using the above list\n",
    "        values,counts=np.unique(outputs,return_counts=True);\n",
    "        #Obtaining the weights correspoding to the training examples\n",
    "        weights=get_weights(neighbours,len(examples));\n",
    "        #Defining the list of weighted distances for each class label\n",
    "        weighted_distances=list();\n",
    "        #Looping over all unique label values\n",
    "        for ind in values:\n",
    "            #Looping over neighbours and summing weights for training examples \n",
    "            #having the class label of interest\n",
    "            sum_weights=0.0;\n",
    "            for idx,dist in neighbours:\n",
    "                if labels[idx]==ind:\n",
    "                    sum_weights+=weights[idx];\n",
    "            weighted_distances.append((ind,sum_weights));\n",
    "        #Sorting the distances in descending order based on the sum_weights parameter\n",
    "        weighted_distances.sort(key=lambda x:x[1],reverse=True);\n",
    "        #Appending the label corresponding to the highest weighted distance \n",
    "        #as the prediction for the current test example\n",
    "        predictions.append(weighted_distances[0][0]);\n",
    "    return predictions;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the knn function to make predictions for the test examples\n",
    "predictions=knn(examples,labels,test_examples);\n",
    "#Printing the predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the results in a .out file with appropriate name\n",
    "with open('19EC30055_P2.out','w') as opf:\n",
    "    for preds in predictions:\n",
    "        opf.write('%d ' % preds);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
